import streamlit as st
import sqlite3
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path

# ============================================
# PAGE CONFIG
# ============================================

st.set_page_config(
    page_title="PISA Math Self-Confidence Explorer",
    page_icon="üìä",
    layout="wide"
)

# ============================================
# DATABASE CONNECTION
# ============================================

@st.cache_resource
def get_db_connection():
    """Erstellt gecachte Datenbankverbindung"""
    db_path = "pisa_2022_germany.db"
    return sqlite3.connect(db_path, check_same_thread=False)

# ============================================
# DATA LOADING FUNCTIONS
# ============================================

@st.cache_data
def load_codebook(_conn, search_term=None):
    """L√§dt Codebook mit optionalem Filter"""
    query = """
    SELECT
        variable_name,
        variable_label,
        data_type
    FROM codebook
    """

    if search_term:
        query += f"""
        WHERE LOWER(variable_label) LIKE LOWER('%{search_term}%')
        OR LOWER(variable_name) LIKE LOWER('%{search_term}%')
        """

    query += " ORDER BY variable_name;"

    return pd.read_sql_query(query, _conn)

@st.cache_data
def load_value_labels(_conn, variable_name):
    """L√§dt Value Labels f√ºr eine Variable (mit deutschen Labels falls vorhanden)"""
    query = f"""
    SELECT
        value,
        label_en as label,
        label_de,
        count,
        percent,
        is_missing_code
    FROM value_labels
    WHERE variable_name = '{variable_name}'
    ORDER BY sort_order, value;
    """
    return pd.read_sql_query(query, _conn)

@st.cache_data
def load_question_text(_conn, variable_name):
    """L√§dt Fragetext f√ºr eine Variable"""
    query = f"""
    SELECT
        question_text_en,
        question_text_de,
        questionnaire_type,
        question_category
    FROM question_text
    WHERE variable_name = '{variable_name}';
    """
    result = pd.read_sql_query(query, _conn)
    return result.iloc[0] if len(result) > 0 else None

@st.cache_data
def load_student_data(_conn, variables):
    """L√§dt Sch√ºlerdaten f√ºr ausgew√§hlte Variablen

    Args:
        _conn: Datenbankverbindung (wird nicht f√ºr Cache-Key verwendet)
        variables: Liste der zu ladenden Variablen
    """
    var_list = ", ".join(variables)
    query = f"""
    SELECT
        {var_list},
        ST004D01T as gender,
        PV1MATH as math_score,
        PV1READ as reading_score,
        PV1SCIE as science_score
    FROM student_data
    WHERE {variables[0]} IS NOT NULL;
    """
    return pd.read_sql_query(query, _conn)

# ============================================
# HELPER FUNCTIONS
# ============================================

def find_math_confidence_vars(conn):
    """Findet alle Mathe-Selbstvertrauens-Variablen (PISA 2022 Indices)"""
    # PISA 2022 nutzt ausschlie√ülich aggregierte Indices
    # Keine einzelnen Items (ST182, ST181) in √∂ffentlichen Daten
    
    # Liste der bekannten Math-Confidence Indices aus Test
    known_indices = [
        'ANXMAT',      # Mathematics Anxiety (WLE)
        'MATHEFF',     # Mathematics self-efficacy
        'MATHMOT',     # Motivation to do well in mathematics
        'MATHPERS',    # Effort and Persistence in Mathematics
        'MATHPREF',    # Preference of Math over other subjects
        'MATHEASE',    # Perception of Math as easier
        'MATHEF21'     # Self-efficacy: reasoning and 21st century
    ]
    
    query = """
    SELECT 
        variable_name,
        variable_label,
        data_type
    FROM codebook
    WHERE variable_name IN ('ANXMAT', 'MATHEFF', 'MATHMOT', 'MATHPERS', 
                            'MATHPREF', 'MATHEASE', 'MATHEF21', 'BELONG', 'ESCS')
    OR (
        variable_label LIKE '%math%' 
        AND (
            variable_label LIKE '%anxiety%'
            OR variable_label LIKE '%efficacy%'
            OR variable_label LIKE '%confidence%'
            OR variable_label LIKE '%motivation%'
            OR variable_label LIKE '%persistence%'
        )
    )
    ORDER BY 
        CASE 
            WHEN variable_name = 'ANXMAT' THEN 1
            WHEN variable_name = 'MATHEFF' THEN 2
            WHEN variable_name = 'MATHMOT' THEN 3
            WHEN variable_name = 'MATHPERS' THEN 4
            WHEN variable_name = 'MATHPREF' THEN 5
            WHEN variable_name = 'MATHEASE' THEN 6
            WHEN variable_name = 'MATHEF21' THEN 7
            ELSE 99
        END;
    """
    return pd.read_sql_query(query, conn)

def calculate_composite_score(df, anxiety_vars, reverse=True):
    """Berechnet Composite Score aus mehreren Items"""
    if reverse:
        # Reverse-code: 5 - value (h√∂herer Score = mehr Confidence)
        composite = sum(5 - df[var] for var in anxiety_vars) / len(anxiety_vars)
    else:
        composite = sum(df[var] for var in anxiety_vars) / len(anxiety_vars)
    return composite

# ============================================
# MAIN APP
# ============================================

def main():
    st.title("üìä PISA 2022 - Mathematics Self-Confidence Explorer")
    st.markdown("**Deutschland-Daten | Fokus: Matheselbstvertrauen & Anxiety**")
    
    # Verwende immer die vollst√§ndige Datenbank
    conn = get_db_connection()
    
    # ============================================
    # TABS
    # ============================================
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìö Variable Explorer",
        "üìä Deskriptive Statistik",
        "üîó Korrelationen",
        "üìà Visualisierungen",
        "üó∫Ô∏è TIMSS-PISA Mapping",
        "üìã Ergebnis√ºbersicht"
    ])
    
    # ============================================
    # TAB 1: VARIABLE EXPLORER
    # ============================================
    
    with tab1:
        st.header("üìö Variable Explorer - Codebook durchsuchen")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            search_term = st.text_input(
                "üîç Suche nach Variablen:",
                placeholder="z.B. 'math anxiety' oder 'ST182'",
                help="Durchsucht Variable Names und Labels"
            )
        
        with col2:
            quick_search = st.selectbox(
                "‚ö° Quick Search:",
                [
                    "Math-Variablen (Standard)",
                    "Math Anxiety Items (mit Fragetext)",
                    "Math Self-Efficacy Items (mit Fragetext)",
                    "Alle Anxiety/Angst/Worry",
                    "Alle Self-Efficacy",
                    "Alle Variablen"
                ]
            )

        # Quick search mapping
        quick_search_terms = {
            "Math-Variablen (Standard)": None,
            "Math Anxiety Items (mit Fragetext)": "ST292",  # Math Anxiety Items mit Fragetexten
            "Math Self-Efficacy Items (mit Fragetext)": "ST29",  # ST290 + ST291 Items
            "Alle Anxiety/Angst/Worry": "anx",  # Findet anxiety, anxious, ANXMAT
            "Alle Self-Efficacy": "effic",  # Findet efficacy, MATHEFF, etc.
            "Alle Variablen": ""  # Leerer String = alle
        }
        
        final_search = search_term if search_term else quick_search_terms[quick_search]

        if final_search is not None:  # None = Standard, "" = alle
            if final_search == "":
                # "Alle Variablen" ausgew√§hlt - zeige wirklich alle
                codebook = load_codebook(conn, None)
                # Kleine Warnung bei vielen Variablen
                if len(codebook) > 500:
                    st.info(f"‚ÑπÔ∏è {len(codebook)} Variablen gefunden. Du kannst die Suchbox nutzen, um zu filtern.")
            else:
                # Suche mit Begriff
                codebook = load_codebook(conn, final_search)
        else:
            # Zeige nur Mathe-relevante Variablen standardm√§√üig
            codebook = find_math_confidence_vars(conn)
        
        st.dataframe(
            codebook,
            use_container_width=True,
            height=400
        )
        
        st.info(f"üìä Gefundene Variablen: **{len(codebook)}**")
        
        # Variable Details
        if len(codebook) > 0:
            st.subheader("üîç Variable Details")
            
            selected_var = st.selectbox(
                "W√§hle Variable f√ºr Details:",
                options=codebook['variable_name'].tolist()
            )
            
            if selected_var:
                var_info = codebook[codebook['variable_name'] == selected_var].iloc[0]

                # Basis-Info
                st.markdown(f"**Variable Name:** `{var_info['variable_name']}`")
                st.markdown(f"**Label:** {var_info['variable_label']}")
                st.markdown(f"**Data Type:** {var_info['data_type']}")

                # Fragetext laden (falls vorhanden) - PROMINENT OBEN
                question = load_question_text(conn, selected_var)
                if question is not None:
                    st.markdown("---")
                    st.markdown("### üìù Fragetext (Question Text)")

                    # Zeige deutschen Text falls vorhanden, sonst englisch
                    if pd.notna(question.get('question_text_de')):
                        st.success(f"**üá©üá™ Deutsch:** {question['question_text_de']}")
                        with st.expander("üá¨üáß Show English text"):
                            st.text(question['question_text_en'])
                    else:
                        st.success(f"**üá¨üáß English:** {question['question_text_en']}")

                    if pd.notna(question.get('questionnaire_type')):
                        st.caption(f"üìã Questionnaire: {question['questionnaire_type']} | Category: {question.get('question_category', 'N/A')}")
                else:
                    st.info("‚ÑπÔ∏è Kein Fragetext vorhanden (aggregierter Index oder keine Question-Items)")

                st.markdown("---")

                # Antwortoptionen in voller Breite
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### üìä Statistik")
                    # Placeholder f√ºr Statistik
                    st.caption("Verf√ºgbar in Tab 2: Deskriptive Statistik")

                with col2:
                    # Value Labels anzeigen
                    value_labels = load_value_labels(conn, selected_var)

                    if len(value_labels) > 0:
                        st.markdown("### üìã Antwortoptionen")
                        
                        # Erstelle sch√∂nere Darstellung
                        display_labels = value_labels.copy()
                        
                        # Zeige deutsche Labels falls vorhanden
                        display_labels['Antwort'] = display_labels.apply(
                            lambda row: f"{row['label_de']}" if pd.notna(row.get('label_de')) 
                            else f"{row['label']}", 
                            axis=1
                        )
                        
                        # Formatiere Prozent falls vorhanden
                        if 'percent' in display_labels.columns and display_labels['percent'].notna().any():
                            display_labels['H√§ufigkeit'] = display_labels.apply(
                                lambda row: f"{row['percent']:.1f}%" if pd.notna(row['percent']) else "",
                                axis=1
                            )
                            cols_to_show = ['value', 'Antwort', 'H√§ufigkeit']
                        else:
                            cols_to_show = ['value', 'Antwort']
                        
                        # Markiere Missing Codes
                        if 'is_missing_code' in display_labels.columns:
                            display_labels['value'] = display_labels.apply(
                                lambda row: f"~~{row['value']}~~" if row.get('is_missing_code') == 1 
                                else str(row['value']),
                                axis=1
                            )
                        
                        st.dataframe(
                            display_labels[cols_to_show],
                            use_container_width=True,
                            hide_index=True
                        )
                        
                        # Hinweis zu Missing Codes
                        if (display_labels.get('is_missing_code') == 1).any():
                            st.caption("~~Durchgestrichene Werte~~ = Missing Codes (97, 98, 99)")
                    else:
                        st.info("‚ÑπÔ∏è Keine Value Labels verf√ºgbar (numerische Variable)")
    
    # ============================================
    # TAB 2: DESKRIPTIVE STATISTIK
    # ============================================
    
    with tab2:
        st.header("üìä Deskriptive Statistik")
        
        # Variable Selection
        st.subheader("üéØ Variablen ausw√§hlen")
        
        st.info("""
        ‚ÑπÔ∏è **PISA 2022 Hinweis:** Die Datenbank enth√§lt aggregierte **Indices** statt einzelner Fragebogen-Items.
        
        **Verf√ºgbare Math-Confidence Indices:**
        - **ANXMAT** = Mathematics Anxiety (h√∂her = mehr Angst) ‚≠ê
        - **MATHEFF** = Mathematics Self-Efficacy (h√∂her = mehr Selbstvertrauen) ‚≠ê
        - **MATHMOT** = Motivation to do well in mathematics
        - **MATHPERS** = Effort and Persistence in Mathematics
        - **MATHPREF** = Preference of Math over other subjects
        - **MATHEASE** = Perception of Math as easier than other subjects
        - **MATHEF21** = Self-efficacy: mathematical reasoning and 21st century skills
        
        ‚≠ê = Empfohlen f√ºr Selbstvertrauens-Analyse
        """)
        
        # Finde alle verf√ºgbaren Math-bezogenen Variablen
        available_vars = load_codebook(conn, 'math')['variable_name'].tolist()

        # Standard: Die 2 wichtigsten Indices f√ºr Math Self-Confidence
        pisa_indices = ['ANXMAT', 'MATHEFF', 'MATHMOT', 'MATHPERS']
        default_vars = [v for v in pisa_indices if v in available_vars][:2]  # Nur die ersten 2

        # Falls keine Indices, zeige alle Math-Variablen
        if not default_vars:
            default_vars = available_vars[:3] if len(available_vars) >= 3 else available_vars

        selected_vars = st.multiselect(
            "W√§hle Variablen f√ºr Analyse:",
            options=available_vars,
            default=default_vars,
            help="Empfohlen: ANXMAT (Anxiety) und MATHEFF (Self-Efficacy)"
        )

        if selected_vars:
            # Daten laden
            df = load_student_data(conn, selected_vars)
            
            # Deskriptive Statistik
            st.subheader("üìà Statistik-√úbersicht")
            
            desc_stats = df[selected_vars + ['math_score']].describe()
            st.dataframe(desc_stats, use_container_width=True)
            
            # Erkl√§rung f√ºr Indices
            st.caption("""
            üìå **PISA Indices Interpretation:**
            - Indices sind standardisiert (Mean ‚âà 0, SD ‚âà 1 im OECD-Durchschnitt)
            - **Negative Werte** = unter OECD-Durchschnitt
            - **Positive Werte** = √ºber OECD-Durchschnitt
            """)
            
            # Missing Values
            st.subheader("üîç Missing Values")
            missing = df[selected_vars].isnull().sum()
            missing_pct = (missing / len(df) * 100).round(2)
            
            missing_df = pd.DataFrame({
                'Variable': missing.index,
                'Missing Count': missing.values,
                'Missing %': missing_pct.values
            })
            
            st.dataframe(missing_df, use_container_width=True)
            
            # Composite Score nur wenn mehrere Variablen gew√§hlt
            if len(selected_vars) >= 2 and 'ANXMAT' in selected_vars and 'MATHEFF' in selected_vars:
                st.subheader("üßÆ Composite Score")
                
                st.info("""
                üìä **Confidence Score Berechnung:**
                - Basiert auf MATHEFF (Self-Efficacy) minus ANXMAT (Anxiety)
                - H√∂here Werte = mehr Selbstvertrauen, weniger Angst
                """)
                
                # Berechne Confidence Score: Self-Efficacy - Anxiety
                df['confidence_score'] = df['MATHEFF'] - df['ANXMAT']
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric(
                        "√ò Math Anxiety",
                        f"{df['ANXMAT'].mean():.3f}",
                        help="ANXMAT Index (0 = OECD Durchschnitt)"
                    )
                
                with col2:
                    st.metric(
                        "√ò Math Self-Efficacy",
                        f"{df['MATHEFF'].mean():.3f}",
                        help="MATHEFF Index (0 = OECD Durchschnitt)"
                    )
                
                with col3:
                    st.metric(
                        "√ò Confidence Score",
                        f"{df['confidence_score'].mean():.3f}",
                        help="MATHEFF - ANXMAT"
                    )
                
                # Zus√§tzliche Statistik
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric(
                        "√ò Math Score",
                        f"{df['math_score'].mean():.0f}",
                        help="PISA Math Performance (Plausible Value 1)"
                    )
                
                with col2:
                    # Korrelation Confidence vs. Performance
                    corr = df[['confidence_score', 'math_score']].corr().iloc[0, 1]
                    st.metric(
                        "Korrelation Confidence ‚Üî Math",
                        f"{corr:.3f}",
                        help="Pearson Korrelation"
                    )
                
                # ============================================
                # KINDERLEICHTE ERKL√ÑRUNGEN (ANXMAT + MATHEFF)
                # ============================================
                
                st.markdown("---")
                
                with st.expander("üë∂ **Einfach erkl√§rt - Was bedeuten diese Zahlen?**", expanded=True):
                    
                    # Berechne Werte
                    n_students = len(df)
                    mean_anxmat = df['ANXMAT'].mean()
                    mean_matheff = df['MATHEFF'].mean()
                    mean_confidence = df['confidence_score'].mean()
                    mean_math = df['math_score'].mean()
                    std_anxmat = df['ANXMAT'].std()
                    std_matheff = df['MATHEFF'].std()
                    
                    # ========== SECTION 1: Was siehst du? ==========
                    st.markdown(f"""
                    ### üìä Was siehst du?
                    
                    Du schaust dir **{n_students:,} deutsche Sch√ºler** an (aus der PISA-Studie).
                    
                    F√ºr jeden haben wir gemessen:
                    - **ANXMAT** = Mathe-Angst (je h√∂her, desto √§ngstlicher)
                    - **MATHEFF** = Selbstvertrauen in Mathe (je h√∂her, desto selbstbewusster)
                    - **Math Score** = Matheleistung in Punkten
                    """)
                    
                    # ========== SECTION 2: Der Durchschnitt erkl√§rt ==========
                    st.markdown("### üéØ Der Durchschnitt erkl√§rt")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # ANXMAT Interpretation
                        if abs(mean_anxmat) < 0.2:
                            anxmat_color = "üü¢"
                            anxmat_text = "**Fast genau beim OECD-Durchschnitt!**"
                            anxmat_detail = "Deutsche Sch√ºler haben eine normale Mathe-Angst - nicht mehr und nicht weniger als der internationale Durchschnitt."
                        elif mean_anxmat > 0.5:
                            anxmat_color = "üî¥"
                            anxmat_text = "**Deutlich √ºber dem OECD-Durchschnitt!**"
                            anxmat_detail = "Deutsche Sch√ºler haben mehr Mathe-Angst als der internationale Durchschnitt. Hier besteht Handlungsbedarf!"
                        elif mean_anxmat > 0:
                            anxmat_color = "üü°"
                            anxmat_text = "**Etwas √ºber dem OECD-Durchschnitt**"
                            anxmat_detail = "Deutsche Sch√ºler haben etwas mehr Mathe-Angst als der internationale Durchschnitt."
                        elif mean_anxmat > -0.5:
                            anxmat_color = "üü¢"
                            anxmat_text = "**Etwas unter dem OECD-Durchschnitt**"
                            anxmat_detail = "Deutsche Sch√ºler haben etwas weniger Mathe-Angst als der internationale Durchschnitt - das ist gut!"
                        else:
                            anxmat_color = "üü¢"
                            anxmat_text = "**Deutlich unter dem OECD-Durchschnitt!**"
                            anxmat_detail = "Deutsche Sch√ºler haben viel weniger Mathe-Angst als der internationale Durchschnitt. Super!"
                        
                        st.markdown(f"""
                        **üò∞ Mathe-Angst: {mean_anxmat:.3f}**
                        
                        {anxmat_color} {anxmat_text}
                        
                        {anxmat_detail}
                        
                        **Merke:** 0 = OECD-Durchschnitt
                        """)
                    
                    with col2:
                        # MATHEFF Interpretation
                        if abs(mean_matheff) < 0.2:
                            matheff_color = "üü¢"
                            matheff_text = "**Fast genau beim OECD-Durchschnitt!**"
                            matheff_detail = "Deutsche Sch√ºler haben ein normales Mathe-Selbstvertrauen - vergleichbar mit dem internationalen Durchschnitt."
                        elif mean_matheff > 0.5:
                            matheff_color = "üü¢"
                            matheff_text = "**Deutlich √ºber dem OECD-Durchschnitt!**"
                            matheff_detail = "Deutsche Sch√ºler haben mehr Selbstvertrauen in Mathe als der internationale Durchschnitt. Super!"
                        elif mean_matheff > 0:
                            matheff_color = "üü¢"
                            matheff_text = "**Etwas √ºber dem OECD-Durchschnitt**"
                            matheff_detail = "Deutsche Sch√ºler haben etwas mehr Selbstvertrauen als der internationale Durchschnitt."
                        elif mean_matheff > -0.5:
                            matheff_color = "üü°"
                            matheff_text = "**Etwas unter dem OECD-Durchschnitt**"
                            matheff_detail = "Deutsche Sch√ºler haben etwas weniger Selbstvertrauen als der internationale Durchschnitt."
                        else:
                            matheff_color = "üî¥"
                            matheff_text = "**Deutlich unter dem OECD-Durchschnitt!**"
                            matheff_detail = "Deutsche Sch√ºler haben deutlich weniger Selbstvertrauen als der internationale Durchschnitt. Hier k√∂nnen Interventionen helfen!"
                        
                        st.markdown(f"""
                        **üí™ Selbstvertrauen: {mean_matheff:.3f}**
                        
                        {matheff_color} {matheff_text}
                        
                        {matheff_detail}
                        
                        **Merke:** 0 = OECD-Durchschnitt
                        """)
                    
                    # ========== SECTION 3: Emoji-Skala ==========
                    st.markdown("### üòä Wo steht Deutschland?")
                    
                    # ANXMAT Skala
                    st.markdown("**üò∞ Mathe-Angst Skala:**")
                    
                    # Berechne Position auf Skala (-3 bis +3, aber zeige -2 bis +2)
                    anxmat_pos = max(-2, min(2, mean_anxmat))
                    scale_positions = [-2, -1, 0, 1, 2]
                    emojis = ["üòäüòä", "üôÇ", "üòê", "üòü", "üò∞üò∞"]
                    
                    # Erstelle Skala-String
                    scale_str = ""
                    for i, pos in enumerate(scale_positions):
                        if abs(anxmat_pos - pos) < 0.3:
                            scale_str += f"**[{emojis[i]}]** "
                        else:
                            scale_str += f"{emojis[i]} "
                    
                    st.markdown(scale_str)
                    st.markdown("‚Üê Wenig Angst&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Viel Angst ‚Üí")
                    
                    # MATHEFF Skala
                    st.markdown("")
                    st.markdown("**üí™ Selbstvertrauen Skala:**")
                    
                    matheff_pos = max(-2, min(2, mean_matheff))
                    emojis_eff = ["üòîüòî", "üòï", "üòê", "üôÇ", "üòäüòä"]
                    
                    scale_str_eff = ""
                    for i, pos in enumerate(scale_positions):
                        if abs(matheff_pos - pos) < 0.3:
                            scale_str_eff += f"**[{emojis_eff[i]}]** "
                        else:
                            scale_str_eff += f"{emojis_eff[i]} "
                    
                    st.markdown(scale_str_eff)
                    st.markdown("‚Üê Wenig Selbstvertrauen&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Viel Selbstvertrauen ‚Üí")
                    
                    # ========== SECTION 4: Die Unterschiede (std) ==========
                    st.markdown("### üìè Wie unterschiedlich sind die Sch√ºler?")
                    
                    # Interpretation der Standardabweichung
                    if std_anxmat > 1.3:
                        std_text = "**Sehr gro√üe Unterschiede!**"
                        std_detail = "Manche Sch√ºler sind total entspannt, andere sehr √§ngstlich. Die Gruppe ist sehr heterogen."
                    elif std_anxmat > 1.0:
                        std_text = "**Gro√üe Unterschiede**"
                        std_detail = "Es gibt deutliche Unterschiede zwischen den Sch√ºlern - manche √§ngstlich, manche entspannt."
                    else:
                        std_text = "**Moderate Unterschiede**"
                        std_detail = "Die Sch√ºler sind sich relativ √§hnlich in ihrer Mathe-Angst."
                    
                    st.markdown(f"""
                    **Standardabweichung (std)** = Wie verschieden sind die Sch√ºler?
                    
                    - ANXMAT: {std_anxmat:.2f} ‚Üí {std_text}
                    - MATHEFF: {std_matheff:.2f}
                    
                    {std_detail}
                    
                    **Visualisiert:**
                    """)
                    
                    # Visuelle Darstellung der Streuung
                    if std_anxmat > 1.2:
                        st.markdown("""
                        ```
                        Entspannt                           √Ñngstlich
                        |                                         |
                        üë§              üë§üë§üë§              üë§üë§
                        ‚Üê Wenige hier   Viele hier   Viele hier ‚Üí
                        ```
                        ‚Üí Das Schulsystem erzeugt **sehr unterschiedliche** Ergebnisse!
                        """)
                    else:
                        st.markdown("""
                        ```
                        Entspannt                           √Ñngstlich
                        |                                         |
                               üë§üë§üë§üë§üë§üë§üë§
                               ‚Üê Die meisten hier ‚Üí
                        ```
                        ‚Üí Die meisten Sch√ºler sind sich √§hnlich.
                        """)
                    
                    # ========== SECTION 5: Die Extremen (min/max) ==========
                    st.markdown("### üéØ Von Minimum bis Maximum")
                    
                    min_anxmat = df['ANXMAT'].min()
                    max_anxmat = df['ANXMAT'].max()
                    min_matheff = df['MATHEFF'].min()
                    max_matheff = df['MATHEFF'].max()
                    min_math = df['math_score'].min()
                    max_math = df['math_score'].max()
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown(f"""
                        **üò∞ Mathe-Angst Spannweite:**
                        
                        ```
                        Entspanntester: {min_anxmat:.2f}
                        Durchschnitt:   {mean_anxmat:.2f}
                        √Ñngstlichster:  {max_anxmat:.2f}
                        
                        Spannweite: {max_anxmat - min_anxmat:.2f} Punkte
                        ```
                        
                        Das hei√üt: Der √§ngstlichste Sch√ºler hat {abs(max_anxmat - min_anxmat):.1f}x mehr Angst als der entspannteste!
                        """)
                    
                    with col2:
                        st.markdown(f"""
                        **üìù Matheleistung Spannweite:**
                        
                        ```
                        Schw√§chster:   {min_math:.0f} Punkte
                        Durchschnitt:  {mean_math:.0f} Punkte
                        St√§rkster:     {max_math:.0f} Punkte
                        
                        Spannweite: {max_math - min_math:.0f} Punkte
                        ```
                        
                        Das hei√üt: Der beste Sch√ºler ist {(max_math/min_math):.1f}x besser als der schw√§chste!
                        """)
                    
                    # ========== SECTION 6: Confidence Score ==========
                    st.markdown("### üèÜ Der Confidence Score")
                    
                    st.markdown(f"""
                    **Formel:** Confidence Score = MATHEFF - ANXMAT
                    
                    **Dein Ergebnis:** {mean_confidence:.3f}
                    """)
                    
                    if mean_confidence > 0.5:
                        confidence_emoji = "üü¢"
                        confidence_text = "**Super! Selbstvertrauen √ºberwiegt deutlich!**"
                        confidence_detail = "Deutsche Sch√ºler haben mehr Selbstvertrauen als Angst. Das ist eine gute Grundlage f√ºr Lernerfolg!"
                    elif mean_confidence > 0:
                        confidence_emoji = "üü¢"
                        confidence_text = "**Gut! Selbstvertrauen √ºberwiegt leicht**"
                        confidence_detail = "Deutsche Sch√ºler haben etwas mehr Selbstvertrauen als Angst."
                    elif mean_confidence > -0.5:
                        confidence_emoji = "üü°"
                        confidence_text = "**Ausgeglichen mit leichtem Angst-√úberhang**"
                        confidence_detail = "Selbstvertrauen und Angst halten sich fast die Waage, mit leichter Tendenz zur Angst."
                    else:
                        confidence_emoji = "üî¥"
                        confidence_text = "**Achtung! Angst √ºberwiegt deutlich!**"
                        confidence_detail = "Deutsche Sch√ºler haben mehr Angst als Selbstvertrauen. Hier sollten Interventionen ansetzen!"
                    
                    st.markdown(f"""
                    {confidence_emoji} {confidence_text}
                    
                    {confidence_detail}
                    """)
                    
                    # Visualisierung
                    st.markdown("**Visualisierung:**")
                    
                    # Erstelle Balance-Waage
                    matheff_bar = "‚ñà" * max(1, int(abs(mean_matheff) * 10))
                    anxmat_bar = "‚ñà" * max(1, int(abs(mean_anxmat) * 10))
                    
                    st.markdown(f"""
                    ```
                    Selbstvertrauen  vs.  Angst
                    {matheff_bar: <20} | {anxmat_bar}
                    {mean_matheff:.2f}           {mean_anxmat:.2f}
                    ```
                    """)
                    
                    if mean_confidence > 0:
                        st.success("‚úÖ Selbstvertrauen ist st√§rker!")
                    elif abs(mean_confidence) < 0.1:
                        st.info("‚öñÔ∏è Fast ausgeglichen")
                    else:
                        st.warning("‚ö†Ô∏è Angst ist st√§rker")
                    
                    # ========== SECTION 7: Was hei√üt das f√ºr dein Projekt? ==========
                    st.markdown("### üí° Was bedeutet das f√ºr dein Projekt?")
                    
                    st.markdown("""
                    **F√ºr deine YouTube-Analyse morgen:**
                    """)
                    
                    # Dynamische Empfehlungen basierend auf Werten
                    recommendations = []
                    
                    if mean_anxmat > 0.3:
                        recommendations.append("üéØ **Suche Videos zu**: 'Mathe-Angst √ºberwinden' (ANXMAT ist erh√∂ht)")
                    
                    if mean_matheff < -0.3:
                        recommendations.append("üéØ **Suche Videos zu**: 'Mathe-Selbstvertrauen aufbauen' (MATHEFF ist niedrig)")
                    
                    if std_anxmat > 1.3:
                        recommendations.append("üéØ **Fokus auf**: Videos f√ºr √§ngstliche Sch√ºler (gro√üe Unterschiede!)")
                    
                    if corr > 0.4:
                        recommendations.append(f"‚úÖ **Wichtig**: Selbstvertrauen korreliert stark mit Leistung ({corr:.2f}) - Videos k√∂nnen wirklich helfen!")
                    
                    if not recommendations:
                        recommendations.append("üéØ **Allgemein**: Suche Videos die Selbstvertrauen st√§rken und Angst reduzieren")
                    
                    for rec in recommendations:
                        st.markdown(rec)
                    
                    st.markdown(f"""
                    
                    **Deine Ausgangslage:**
                    - {n_students:,} Sch√ºler analysiert
                    - Durchschnittliche Matheleistung: {mean_math:.0f} Punkte
                    - Korrelation Confidence ‚Üî Leistung: {corr:.3f}
                    
                    ‚Üí Nutze diese Zahlen morgen als **Baseline** f√ºr deine YouTube-Strategien!
                    """)
            
            elif len(selected_vars) >= 1:
                # Zeige Durchschnitte f√ºr einzelne Variablen
                st.subheader("üìä Durchschnittswerte")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    for var in selected_vars[:len(selected_vars)//2 + 1]:
                        st.metric(
                            f"√ò {var}",
                            f"{df[var].mean():.3f}",
                            help=f"Durchschnitt f√ºr {var}"
                        )
                
                with col2:
                    for var in selected_vars[len(selected_vars)//2 + 1:]:
                        st.metric(
                            f"√ò {var}",
                            f"{df[var].mean():.3f}",
                            help=f"Durchschnitt f√ºr {var}"
                        )
                    
                    st.metric(
                        "√ò Math Score",
                        f"{df['math_score'].mean():.0f}",
                        help="PISA Math Performance"
                    )
                
                # ============================================
                # KINDERLEICHTE ERKL√ÑRUNGEN (EINZELVARIABLEN)
                # ============================================
                
                st.markdown("---")
                
                with st.expander("üë∂ **Einfach erkl√§rt - Was bedeuten diese Zahlen?**", expanded=True):
                    
                    n_students = len(df)
                    mean_math = df['math_score'].mean()
                    
                    st.markdown(f"""
                    ### üìä Was siehst du?
                    
                    Du schaust dir **{n_students:,} deutsche Sch√ºler** an (aus der PISA-Studie).
                    """)
                    
                    # F√ºr jede Variable eine Interpretation
                    for var in selected_vars:
                        mean_val = df[var].mean()
                        std_val = df[var].std()
                        min_val = df[var].min()
                        max_val = df[var].max()
                        
                        # Dynamische Interpretation
                        if abs(mean_val) < 0.2:
                            color = "üü¢"
                            text = "Fast genau beim OECD-Durchschnitt"
                        elif mean_val < -0.5:
                            color = "üü¢"
                            text = "Deutlich unter OECD-Durchschnitt"
                        elif mean_val < 0:
                            color = "üü°"
                            text = "Etwas unter OECD-Durchschnitt"
                        elif mean_val < 0.5:
                            color = "üü°"
                            text = "Etwas √ºber OECD-Durchschnitt"
                        else:
                            color = "üî¥"
                            text = "Deutlich √ºber OECD-Durchschnitt"
                        
                        st.markdown(f"""
                        ### {var}
                        
                        **Durchschnitt:** {mean_val:.3f} {color}
                        
                        **Interpretation:** {text}
                        
                        **Spannweite:** Von {min_val:.2f} bis {max_val:.2f} ({max_val - min_val:.2f} Punkte Unterschied)
                        
                        **Standardabweichung:** {std_val:.2f} {'(Gro√üe Unterschiede!)' if std_val > 1.2 else '(Moderate Unterschiede)'}
                        
                        ---
                        """)
                    
                    # Matheleistung
                    st.markdown(f"""
                    ### üìù Matheleistung
                    
                    **Durchschnitt:** {mean_math:.0f} Punkte
                    
                    **PISA-Levels:**
                    - Level 1 (358-420): Grundkenntnisse
                    - Level 2 (420-482): Basiskompetenzen
                    - Level 3 (482-545): Solide Kenntnisse ‚Üê {'**DU BIST HIER**' if 482 <= mean_math <= 545 else ''}
                    - Level 4 (545-607): Gut
                    - Level 5 (607-669): Sehr gut
                    
                    üí° **Was hei√üt das f√ºr dein Projekt?**
                    
                    Nutze diese Werte morgen als Baseline f√ºr deine YouTube-Analyse!
                    """)
        else:
            st.warning("‚ö†Ô∏è Bitte w√§hle mindestens eine Variable aus.")
    
    # ============================================
    # TAB 3: KORRELATIONEN & ZUSAMMENH√ÑNGE
    # ============================================
    
    with tab3:
        st.header("üîó Korrelationen & Zusammenh√§nge")
        st.markdown("*Wie h√§ngen Angst, Selbstvertrauen und Leistung zusammen?*")
        
        # Check ob Daten verf√ºgbar
        if 'df' not in locals() or not selected_vars:
            st.warning("‚ö†Ô∏è Bitte w√§hle erst Variablen in Tab 2 aus.")
        else:
            # Sub-Tabs erstellen
            subtab1, subtab2 = st.tabs([
                "üìñ Story & Erkl√§rung", 
                "üìä Technische Analyse"
            ])
            
            # ============================================
            # SUB-TAB 1: STORY & ERKL√ÑRUNG (NEU)
            # ============================================
            
            with subtab1:
                st.title("üìä Die Mathe-Gleichung des Selbstvertrauens")
                st.markdown("*Eine evidenzbasierte Analyse (PISA 2022 Deutschland)*")
                st.markdown("---")
                
                # Kapitel 1: Forschungsfrage & Kontext
                with st.expander("1Ô∏è‚É£ FORSCHUNGSFRAGE & KONTEXT"):
                    st.markdown("""
                    ### Die Beobachtung
                    
                    In deutschen Klassenzimmern beobachten wir ein Paradox:
                    
                    Zwei Sch√ºlerinnen mit vergleichbarer kognitiver Leistungsf√§higkeit,
                    gleichem sozio√∂konomischen Hintergrund, gleicher Lernzeit.
                    
                    **Eine erzielt 493 Punkte, die andere 420.**
                    
                    Der Unterschied: nicht Intelligenz - sondern **Selbstwirksamkeitserwartung**.
                    
                    Mit PISA 2022 k√∂nnen wir diesen Zusammenhang quantifizieren.
                    
                    ---
                    
                    ### Zentrale Forschungsfragen
                    
                    1. **Wie stark** ist der Zusammenhang zwischen affektiven Faktoren und Leistung?
                    2. **Welcher Faktor** ist einflussreicher: Angst oder Selbstwirksamkeit?
                    3. **Welche praktischen Implikationen** ergeben sich f√ºr Interventionen?
                    
                    ---
                    
                    ### Einordnung in die Bildungsforschung
                    
                    **Theoretischer Rahmen:**
                    - Selbstwirksamkeitstheorie (Bandura, 1997)
                    - Expectancy-Value-Theory (Eccles & Wigfield, 2002)
                    - Control-Value Theory of Achievement Emotions (Pekrun, 2006)
                    
                    **Internationale Befunde:**
                    - Meta-Analyse Richardson et al. (2012): r(Self-Efficacy, Performance) ‚âà 0.50
                    - Hattie's Visible Learning: Effektst√§rke d = 0.92 (Self-Efficacy)
                    - OECD PISA 2018: Korrelation ~0.54 (international)
                    
                    **Unser Beitrag:**
                    Aktualisierte Analyse mit PISA 2022 Deutschland-Daten
                    """)
                
                # Kapitel 2: Methodik & Datengrundlage
                with st.expander("2Ô∏è‚É£ METHODIK & DATENGRUNDLAGE"):
                    st.markdown(f"""
                    ### Stichprobe
                    
                    **PISA 2022 Deutschland**
                    - N = {len(df):,} Sch√ºlerinnen und Sch√ºler
                    - Alter: 15 Jahre
                    - Repr√§sentative Stichprobe aller Bundesl√§nder
                    - Stratifiziertes Cluster-Sampling
                    
                    ---
                    
                    ### Konstrukte & Messinstrumente
                    
                    **ANXMAT - Mathematics Anxiety**
                    - WLE-Index (Weighted Likelihood Estimate)
                    - Standardisiert: M = 0, SD = 1 (OECD-Durchschnitt)
                    - Basiert auf Skala zur Mathematikangst
                    - H√∂here Werte = mehr Angst
                    
                    **MATHEFF - Mathematics Self-Efficacy**
                    - WLE-Index (Weighted Likelihood Estimate)
                    - Standardisiert: M = 0, SD = 1 (OECD-Durchschnitt)
                    - Basiert auf Skala zur Selbstwirksamkeitserwartung
                    - H√∂here Werte = mehr Selbstvertrauen
                    
                    **PV1MATH - Mathematikleistung**
                    - Plausible Value 1 (von 10 PVs)
                    - PISA-Skala: M = 500, SD = 100 (internationale Norm)
                    - Misst mathematische Kompetenz in realit√§tsnahen Kontexten
                    
                    ---
                    
                    ### Analysemethode
                    
                    **Korrelationsanalyse**
                    - Methode: Pearson's r (Produkt-Moment-Korrelation)
                    - Signifikanzniveau: Œ± = .05 (zweiseitig)
                    - Missing Data: Listwise deletion
                    - Effektst√§rken nach Cohen (1988):
                      - |r| = 0.1 ‚Üí kleiner Effekt
                      - |r| = 0.3 ‚Üí mittlerer Effekt
                      - |r| = 0.5 ‚Üí gro√üer Effekt
                    
                    ---
                    
                    ### Qualit√§tssicherung
                    
                    - ‚úÖ Stichprobengr√∂√üe ausreichend (N > 5.000)
                    - ‚úÖ Power-Analyse: 1-Œ≤ > .99
                    - ‚úÖ Normalit√§tsannahme: Bei N > 30 durch CLT erf√ºllt
                    - ‚úÖ Linearit√§tscheck durchgef√ºhrt
                    - ‚ö†Ô∏è Limitation: Querschnittsdaten (keine Kausalit√§t)
                    """)
                
                # Kapitel 3: Zentrale Befunde (expanded by default)
                with st.expander("3Ô∏è‚É£ ZENTRALE BEFUNDE", expanded=True):
                    st.markdown("### Die Korrelationen im Detail")
                    
                    # Pr√ºfe ob ANXMAT und MATHEFF vorhanden sind
                    if 'ANXMAT' in selected_vars and 'MATHEFF' in selected_vars:
                        
                        # Berechne Korrelationen
                        corr_anxmat = df[['ANXMAT', 'math_score']].corr().iloc[0, 1]
                        corr_matheff = df[['MATHEFF', 'math_score']].corr().iloc[0, 1]
                        
                        # R¬≤ berechnen
                        r2_anxmat = corr_anxmat ** 2
                        r2_matheff = corr_matheff ** 2
                        
                        # Key Findings Box
                        st.success(f"""
                        **üîç Zentrale Befunde:**
                        
                        - **MATHEFF (Selbstwirksamkeit)**: r = {corr_matheff:.3f}, R¬≤ = {r2_matheff:.1%} ‚Üí Starke positive Korrelation
                        - **ANXMAT (Angst)**: r = {corr_anxmat:.3f}, R¬≤ = {r2_anxmat:.1%} ‚Üí Mittlere negative Korrelation
                        - **Effektst√§rken-Verh√§ltnis**: Selbstwirksamkeit ist {abs(corr_matheff/corr_anxmat):.2f}x einflussreicher als Angst
                        """)
                        
                        st.markdown("---")
                        
                        # ========================================
                        # VISUALISIERUNG 1: Korrelations-Landschaft
                        # ========================================
                        
                        st.markdown("#### üìä Visualisierung 1: Die Korrelations-Landschaft")
                        
                        # W√§hle welche Variable gezeigt werden soll
                        viz_var = st.radio(
                            "W√§hle Variable:",
                            options=['MATHEFF', 'ANXMAT'],
                            format_func=lambda x: 'üí™ Selbstwirksamkeit (MATHEFF)' if x == 'MATHEFF' else 'üò∞ Angst (ANXMAT)',
                            horizontal=True
                        )
                        
                        # Erstelle Scatter Plot mit Regression
                        if viz_var == 'MATHEFF':
                            color = '#2E7D32'  # Gr√ºn
                            title = 'Selbstwirksamkeit & Mathematikleistung'
                            xlabel = 'MATHEFF (Selbstwirksamkeit)'
                            corr_value = corr_matheff
                            direction = "positiv"
                            interpretation = "Je h√∂her die Selbstwirksamkeit, desto besser die Matheleistung"
                        else:
                            color = '#C62828'  # Rot
                            title = 'Mathematikangst & Mathematikleistung'
                            xlabel = 'ANXMAT (Angst)'
                            corr_value = corr_anxmat
                            direction = "negativ"
                            interpretation = "Je h√∂her die Angst, desto schlechter die Matheleistung"
                        
                        fig = px.scatter(
                            df,
                            x=viz_var,
                            y='math_score',
                            opacity=0.4,
                            trendline='ols',
                            title=f'{title} (N = {len(df):,})',
                            labels={
                                viz_var: xlabel,
                                'math_score': 'Mathematikleistung (PISA-Punkte)'
                            },
                            color_discrete_sequence=[color]
                        )
                        
                        # Layout anpassen
                        fig.update_layout(
                            height=500,
                            hovermode='closest',
                            plot_bgcolor='#FAFAFA',
                            showlegend=False
                        )
                        
                        # Achsen-Styling
                        fig.update_xaxes(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='#E0E0E0',
                            zeroline=True,
                            zerolinewidth=2,
                            zerolinecolor='#424242'
                        )
                        fig.update_yaxes(
                            showgrid=True,
                            gridwidth=1,
                            gridcolor='#E0E0E0'
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Interpretation
                        st.info(f"""
                        **üìä Interpretation:**
                        
                        - **Korrelation:** r = {corr_value:.3f} (p < .001) ‚Üí {direction}er, {'starker' if abs(corr_value) > 0.5 else 'mittlerer'} Zusammenhang
                        - **Varianzaufkl√§rung:** R¬≤ = {(corr_value**2):.1%} der Leistungsunterschiede erkl√§rbar
                        - **Praktisch:** {interpretation}
                        - **Streuung:** Punktewolke zeigt individuelle Unterschiede trotz Trend
                        """)
                        
                        st.markdown("---")
                        
                        # ========================================
                        # VISUALISIERUNG 2: Effektst√§rken-Komparator
                        # ========================================
                        
                        st.markdown("#### üéØ Visualisierung 2: Effektst√§rken-Komparator")
                        
                        st.markdown("""
                        **Wie stark ist der Effekt im Vergleich zu anderen Bildungsfaktoren?**
                        
                        Zum Einordnen der Effektst√§rken nutzen wir Benchmarks aus der Bildungsforschung:
                        """)
                        
                        # Erstelle Benchmark-Daten
                        benchmark_data = pd.DataFrame([
                            {'Faktor': 'MATHEFF\n(Selbstwirksamkeit)', 'Korrelation': abs(corr_matheff), 
                             'R¬≤': r2_matheff, 'Typ': 'Unsere Analyse'},
                            {'Faktor': 'Sozio√∂konomischer\nStatus (ESCS)', 'Korrelation': 0.450, 
                             'R¬≤': 0.203, 'Typ': 'Vergleichswert'},
                            {'Faktor': 'ANXMAT\n(Angst)', 'Korrelation': abs(corr_anxmat), 
                             'R¬≤': r2_anxmat, 'Typ': 'Unsere Analyse'},
                            {'Faktor': 'Geschlecht', 'Korrelation': 0.150, 
                             'R¬≤': 0.023, 'Typ': 'Vergleichswert'},
                        ])
                        
                        benchmark_data = benchmark_data.sort_values('Korrelation', ascending=True)
                        
                        # Farbcodierung
                        colors = benchmark_data['Typ'].map({
                            'Unsere Analyse': '#1565C0',
                            'Vergleichswert': '#757575'
                        })
                        
                        fig = go.Figure()
                        
                        # Balken mit R¬≤-Annotationen
                        fig.add_trace(go.Bar(
                            y=benchmark_data['Faktor'],
                            x=benchmark_data['Korrelation'],
                            orientation='h',
                            marker=dict(
                                color=colors,
                                line=dict(color='white', width=2)
                            ),
                            text=[f"r={r:.3f}<br>R¬≤={r2:.1%}" for r, r2 in 
                                  zip(benchmark_data['Korrelation'], benchmark_data['R¬≤'])],
                            textposition='outside',
                            hovertemplate='<b>%{y}</b><br>Korrelation: %{x:.3f}<extra></extra>'
                        ))
                        
                        fig.update_layout(
                            title='Effektst√§rken im Vergleich',
                            xaxis_title='Korrelation (Betrag)',
                            yaxis_title='',
                            height=400,
                            plot_bgcolor='#FAFAFA',
                            showlegend=False,
                            xaxis=dict(range=[0, 0.7])
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Interpretation
                        st.success(f"""
                        **üí° Key Insight:**
                        
                        Selbstwirksamkeit (r = {corr_matheff:.3f}) erkl√§rt **mehr Leistungsvarianz** 
                        als sozio√∂konomischer Status (r ‚âà 0.45)!
                        
                        Das hei√üt: **Affektive Faktoren sind keine "Soft Skills"** - 
                        sie sind harte Leistungspr√§diktoren und damit valide Ansatzpunkte f√ºr Interventionen.
                        """)
                        
                        st.markdown("---")
                        
                        # ========================================
                        # VISUALISIERUNG 3: Vier-Quadranten-Matrix
                        # ========================================
                        
                        st.markdown("#### üó∫Ô∏è Visualisierung 3: Vier-Quadranten-Matrix")
                        
                        st.markdown("""
                        **Welche Sch√ºlergruppen gibt es?**
                        
                        Durch Kombination von Selbstwirksamkeit und Angst entstehen vier Profile:
                        """)
                        
                        # Berechne Quadranten (Median-Split)
                        median_matheff = df['MATHEFF'].median()
                        median_anxmat = df['ANXMAT'].median()
                        
                        df['quadrant'] = 'Q4'  # Default
                        
                        # Q1: Hohe Selbstwirksamkeit, Niedrige Angst
                        df.loc[(df['MATHEFF'] >= median_matheff) & (df['ANXMAT'] < median_anxmat), 'quadrant'] = 'Q1'
                        
                        # Q2: Hohe Selbstwirksamkeit, Hohe Angst
                        df.loc[(df['MATHEFF'] >= median_matheff) & (df['ANXMAT'] >= median_anxmat), 'quadrant'] = 'Q2'
                        
                        # Q3: Niedrige Selbstwirksamkeit, Hohe Angst
                        df.loc[(df['MATHEFF'] < median_matheff) & (df['ANXMAT'] >= median_anxmat), 'quadrant'] = 'Q3'
                        
                        # Q4: Niedrige Selbstwirksamkeit, Niedrige Angst
                        df.loc[(df['MATHEFF'] < median_matheff) & (df['ANXMAT'] < median_anxmat), 'quadrant'] = 'Q4'
                        
                        # Berechne Statistiken pro Quadrant
                        quadrant_stats = df.groupby('quadrant').agg({
                            'math_score': ['mean', 'count']
                        }).round(0)
                        quadrant_stats.columns = ['√ò Leistung', 'N']
                        quadrant_stats['Anteil'] = (quadrant_stats['N'] / len(df) * 100).round(1)
                        
                        # Labels f√ºr Quadranten
                        quadrant_labels = {
                            'Q1': 'Q1: Optimal\n(Hohe Selbstwirksamkeit,\nNiedrige Angst)',
                            'Q2': 'Q2: Ambivalent\n(Hohe Selbstwirksamkeit,\nHohe Angst)',
                            'Q3': 'Q3: Risikogruppe\n(Niedrige Selbstwirksamkeit,\nHohe Angst)',
                            'Q4': 'Q4: Indifferent\n(Niedrige Selbstwirksamkeit,\nNiedrige Angst)'
                        }
                        
                        # Scatter Plot mit Quadranten
                        df['quadrant_label'] = df['quadrant'].map(quadrant_labels)
                        
                        fig = px.scatter(
                            df,
                            x='MATHEFF',
                            y='ANXMAT',
                            color='quadrant_label',
                            color_discrete_map={
                                quadrant_labels['Q1']: '#43A047',  # Gr√ºn
                                quadrant_labels['Q2']: '#FDD835',  # Gelb
                                quadrant_labels['Q3']: '#E53935',  # Rot
                                quadrant_labels['Q4']: '#1E88E5'   # Blau
                            },
                            opacity=0.6,
                            title=f'Sch√ºlerprofile nach Selbstwirksamkeit & Angst (N = {len(df):,})',
                            labels={
                                'MATHEFF': 'Selbstwirksamkeit (MATHEFF)',
                                'ANXMAT': 'Angst (ANXMAT)',
                                'quadrant_label': 'Profil'
                            },
                            hover_data={'math_score': ':.0f'}
                        )
                        
                        # Median-Linien hinzuf√ºgen
                        fig.add_hline(y=median_anxmat, line_dash="dash", line_color="#424242", opacity=0.5)
                        fig.add_vline(x=median_matheff, line_dash="dash", line_color="#424242", opacity=0.5)
                        
                        fig.update_layout(
                            height=600,
                            plot_bgcolor='#FAFAFA',
                            legend=dict(
                                orientation="v",
                                yanchor="top",
                                y=0.99,
                                xanchor="left",
                                x=0.01,
                                bgcolor="rgba(255,255,255,0.9)"
                            )
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Statistik-Tabelle
                        st.markdown("**üìä Statistik nach Quadranten:**")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        quadrants = ['Q1', 'Q2', 'Q3', 'Q4']
                        colors_box = ['#43A047', '#FDD835', '#E53935', '#1E88E5']
                        labels_short = ['Optimal', 'Ambivalent', 'Risiko', 'Indifferent']
                        
                        for i, (col, q, color, label) in enumerate(zip([col1, col2, col3, col4], 
                                                                         quadrants, colors_box, labels_short)):
                            with col:
                                if q in quadrant_stats.index:
                                    st.markdown(f"""
                                    <div style="background-color: {color}20; padding: 15px; border-radius: 10px; border-left: 5px solid {color}">
                                        <h4 style="margin: 0; color: {color}">{label}</h4>
                                        <p style="margin: 5px 0;"><b>{quadrant_stats.loc[q, 'Anteil']:.1f}%</b> der Sch√ºler</p>
                                        <p style="margin: 5px 0;">√ò {quadrant_stats.loc[q, '√ò Leistung']:.0f} Punkte</p>
                                        <p style="margin: 5px 0; font-size: 0.9em;">N = {quadrant_stats.loc[q, 'N']:.0f}</p>
                                    </div>
                                    """, unsafe_allow_html=True)
                        
                        st.markdown("---")
                        
                        # Handlungsempfehlungen pro Quadrant
                        st.markdown("**üí° Interventionsempfehlungen nach Profil:**")
                        
                        with st.expander("Q1: Optimal (Gr√ºn) - F√∂rdern & Herausfordern"):
                            st.markdown("""
                            **Charakteristika:**
                            - Hohe Selbstwirksamkeit + Niedrige Angst
                            - Beste Leistungsgruppe
                            - Intrinsisch motiviert
                            
                            **Empfohlene Ma√ünahmen:**
                            - ‚úÖ Challenge & Extension: Anspruchsvolle Aufgaben anbieten
                            - ‚úÖ Peer-Tutoring: Als Tutoren f√ºr andere Sch√ºler einsetzen
                            - ‚úÖ Selbstreguliertes Lernen: Autonomie f√∂rdern
                            - ‚ùå Keine Intervention n√∂tig (Ressourcen f√ºr Risikogruppen)
                            """)
                        
                        with st.expander("Q2: Ambivalent (Gelb) - Pr√ºfungsangst adressieren"):
                            st.markdown("""
                            **Charakteristika:**
                            - Hohe Selbstwirksamkeit + Hohe Angst
                            - "Ich kann es, aber ich habe Angst"
                            - Pr√ºfungsangst, keine F√§higkeitsangst
                            
                            **Empfohlene Ma√ünahmen:**
                            - ‚úÖ Entspannungstechniken: Progressive Muskelrelaxation
                            - ‚úÖ Pr√ºfungssimulationen: Angst durch Gew√∂hnung reduzieren
                            - ‚úÖ Kognitive Umstrukturierung: Katastrophisierende Gedanken hinterfragen
                            - ‚ö†Ô∏è Fokus auf Angstreduktion, nicht Selbstwirksamkeit
                            """)
                        
                        with st.expander("Q3: Risikogruppe (Rot) - H√∂chste Priorit√§t!"):
                            st.markdown("""
                            **Charakteristika:**
                            - Niedrige Selbstwirksamkeit + Hohe Angst
                            - Schw√§chste Leistungsgruppe
                            - "Ich kann es nicht und ich habe Angst"
                            - Vermeidungsverhalten wahrscheinlich
                            
                            **Empfohlene Ma√ünahmen:**
                            - üö® **Priorit√§t 1 f√ºr Interventionen!**
                            - ‚úÖ Mastery Experiences: Garantierte Erfolgserlebnisse schaffen
                            - ‚úÖ Strukturierte Unterst√ºtzung: Kleinschrittige Aufgaben
                            - ‚úÖ Attributionstraining: Erfolge auf Anstrengung zur√ºckf√ºhren
                            - ‚úÖ Peer-Modelle: "Wenn die das k√∂nnen, kann ich das auch"
                            - ‚úÖ Individuelle Betreuung: Mentoring, Tutoring
                            """)
                        
                        with st.expander("Q4: Indifferent (Blau) - Motivation wecken"):
                            st.markdown("""
                            **Charakteristika:**
                            - Niedrige Selbstwirksamkeit + Niedrige Angst
                            - "Ich kann es nicht, aber es ist mir auch egal"
                            - Mangelnde Motivation, gelangweilt
                            
                            **Empfohlene Ma√ünahmen:**
                            - ‚úÖ Relevanz herstellen: Alltagsbezug von Mathe zeigen
                            - ‚úÖ Interessensorientierung: An Hobbys ankn√ºpfen
                            - ‚úÖ Erfolgserlebnisse: Selbstwirksamkeit durch Erfolge aufbauen
                            - ‚úÖ Growth Mindset: "Du kannst es lernen!"
                            - ‚ö†Ô∏è Zuerst Motivation wecken, dann Kompetenzen aufbauen
                            """)
                        
                    else:
                        st.warning("""
                        ‚ö†Ô∏è **F√ºr vollst√§ndige Analysen ben√∂tigt:**
                        
                        Bitte w√§hle in Tab 2 die Variablen **ANXMAT** und **MATHEFF** aus,
                        um alle Visualisierungen in diesem Kapitel zu sehen.
                        
                        Diese beiden Indizes sind zentral f√ºr die Analyse affektiver Faktoren.
                        """)
                        
                        # Zeige trotzdem verf√ºgbare Korrelationen
                        st.markdown("**Verf√ºgbare Korrelationen mit den aktuell gew√§hlten Variablen:**")
                        
                        for var in selected_vars:
                            if var in df.columns:
                                corr = df[[var, 'math_score']].corr().iloc[0, 1]
                                st.metric(
                                    label=f"Korrelation: {var} ‚Üî Matheleistung",
                                    value=f"{corr:.3f}"
                                )
                
                # Kapitel 4: Einordnung & Vergleich
                with st.expander("4Ô∏è‚É£ EINORDNUNG & VERGLEICH"):
                    st.markdown("""
                    ### Benchmark mit internationaler Forschung
                    
                    **Unser Befund im Vergleich:**
                    
                    | Studie | Jahr | Stichprobe | r (Self-Efficacy) | r (Anxiety) |
                    |--------|------|------------|-------------------|-------------|
                    | Richardson et al. | 2012 | Meta-Analyse | 0.50 | -0.34 |
                    | OECD PISA | 2018 | International | 0.54 | -0.38 |
                    | **Unsere Analyse** | **2022** | **Deutschland** | **?** | **?** |
                    
                    ‚Üí Werte werden dynamisch aus den Daten eingef√ºgt
                    
                    ---
                    
                    ### Einordnung nach Hattie's Visible Learning
                    
                    **Effektst√§rken (d) f√ºr Leistung:**
                    - Self-Efficacy: d = 0.92 ‚Üí **sehr hoch**
                    - Teacher-Student-Relationship: d = 0.72
                    - Feedback: d = 0.70
                    - Socioeconomic Status: d = 0.57
                    
                    **Umrechnung:** r = 0.567 entspricht ca. d ‚âà 1.3 (sehr starker Effekt!)
                    
                    ---
                    
                    ### ‚ö†Ô∏è Methodische Limitation: Querschnitt vs. Kausalit√§t
                    
                    **Was unsere Daten zeigen:**
                    - ‚úÖ Es gibt einen **Zusammenhang** zwischen Selbstwirksamkeit und Leistung
                    - ‚úÖ Dieser Zusammenhang ist **statistisch signifikant** und **praktisch bedeutsam**
                    - ‚úÖ Die **Effektst√§rke** rechtfertigt Interventionen
                    
                    **Was unsere Daten NICHT zeigen:**
                    - ‚ùå Ob Selbstwirksamkeit die **Ursache** f√ºr bessere Leistung ist
                    - ‚ùå Oder ob gute Leistung zu mehr Selbstwirksamkeit f√ºhrt
                    - ‚ùå Oder ob ein dritter Faktor beides beeinflusst
                    
                    **F√ºr kausale Aussagen ben√∂tigen wir:**
                    - L√§ngsschnitt-Designs (Messung zu mehreren Zeitpunkten)
                    - Interventionsstudien (Experimental-/Kontrollgruppe)
                    - Strukturgleichungsmodelle mit Mediationsanalysen
                    
                    **Dennoch gerechtfertigt:**
                    Die internationale Evidenz aus experimentellen Studien zeigt,
                    dass Selbstwirksamkeits-Interventionen tats√§chlich kausal 
                    zu Leistungsverbesserungen f√ºhren (siehe Meta-Analysen).
                    
                    Unsere Korrelationen **best√§tigen** diesen bekannten Zusammenhang
                    f√ºr die aktuelle deutsche Kohorte.
                    """)
                
                # Kapitel 5: Implikationen f√ºr die Praxis
                with st.expander("5Ô∏è‚É£ IMPLIKATIONEN F√úR DIE PRAXIS"):
                    st.markdown("""
                    ### Zentrale Handlungsempfehlungen
                    
                    Basierend auf unseren Befunden und der internationalen Evidenz:
                    
                    ---
                    
                    #### 1. Priorisierung: Selbstwirksamkeit vor Angstreduktion
                    
                    **Warum?**
                    - Selbstwirksamkeit zeigt st√§rkeren Zusammenhang mit Leistung
                    - Positive Kompetenz√ºberzeugungen sind nachhaltiger als Angstreduktion
                    - Selbstwirksamkeit hat Transfer-Effekte auf andere Dom√§nen
                    
                    **Wie?**
                    - Fokus auf **Erfolgserlebnisse** (Mastery Experiences)
                    - **Stellvertretende Erfahrungen** (Modeling durch Peers)
                    - **Positives Feedback** auf Prozess, nicht nur Ergebnis
                    - **Realistische Zielsetzungen** mit erreichbaren Teilschritten
                    
                    ---
                    
                    #### 2. Evidenzbasierte Interventionsans√§tze
                    
                    **Top 3 nach Evidenzlage:**
                    
                    **A) Attributionstraining**
                    - Erfolge auf Anstrengung (kontrollierbar) zur√ºckf√ºhren
                    - Misserfolge als Lerngelegenheiten reframen
                    - Growth Mindset f√∂rdern
                    - Effektst√§rke: d ‚âà 0.6-0.8
                    
                    **B) Strukturierte Erfolgserlebnisse**
                    - Aufgaben mit ansteigendem Schwierigkeitsgrad
                    - "Productive Struggle" erm√∂glichen
                    - Kleine Erfolge sichtbar machen
                    - Effektst√§rke: d ‚âà 0.5-0.7
                    
                    **C) Peer-Assisted Learning**
                    - Erfolgreiche Mitsch√ºler als Modelle
                    - "Wenn die das k√∂nnen, kann ich das auch"
                    - Tutoring-Systeme (Tutor profitiert auch!)
                    - Effektst√§rke: d ‚âà 0.5-0.6
                    
                    ---
                    
                    #### 3. Identifikation von Risikogruppen
                    
                    **Wer profitiert am meisten?**
                    
                    Sch√ºler:innen mit:
                    - Niedriger Selbstwirksamkeit + hoher Angst ‚Üí **Priorit√§t 1**
                    - Niedriger Selbstwirksamkeit + niedrige Angst ‚Üí **Priorit√§t 2**
                    - Hoher Selbstwirksamkeit + hoher Angst ‚Üí **Pr√ºfungsangst-Fokus**
                    
                    **Screening-Fragen f√ºr Lehrkr√§fte:**
                    1. "Glaubt der/die Sch√ºler:in an eigene F√§higkeiten?"
                    2. "Zeigt er/sie Vermeidungsverhalten?"
                    3. "Spricht er/sie √ºber vergangene Misserfolgserfahrungen?"
                    
                    ---
                    
                    #### 4. Systemische Perspektive: Schulkultur
                    
                    **√úber Individualinterventionen hinaus:**
                    
                    - **Fehlerkultur**: Fehler als Lernchancen normalisieren
                    - **Heterogene Leistungserwartungen**: Differenzierung erm√∂glichen
                    - **Diagnostische Kompetenz**: Lehrkr√§fte in Selbstwirksamkeits-Diagnostik schulen
                    - **Elternarbeit**: Eltern f√ºr supportive Attributionen sensibilisieren
                    
                    ---
                    
                    ### üì• Materialien f√ºr die Praxis
                    
                    **Handreichungen (entwickelbar):**
                    - ‚úÖ Leitfaden: Selbstwirksamkeit im Matheunterricht f√∂rdern
                    - ‚úÖ Fragebogen: Selbstwirksamkeits-Screening (5 Minuten)
                    - ‚úÖ Interventionskatalog: 20 evidenzbasierte Ma√ünahmen
                    - ‚úÖ Eltern-Information: "Wie unterst√ºtze ich mein Kind?"
                    
                    **Fortbildungsmodule:**
                    - Modul 1: Grundlagen affektiver Faktoren (2h)
                    - Modul 2: Diagnostik im Klassenraum (3h)
                    - Modul 3: Interventionen praktisch umsetzen (4h)
                    """)
                
                # Download-Bereich
                st.markdown("---")
                st.markdown("### üì• Materialien & Export")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("""
                    **Technische Berichte**
                    - üìÑ Methodenbericht (PDF)
                    - üìä Datenexport (CSV)
                    - üìà Syntax-Datei (Python)
                    """)
                
                with col2:
                    st.markdown("""
                    **Pr√§sentationen**
                    - üéØ Lehrerfortbildung (PPTX)
                    - üë™ Elternabend (PPTX)
                    - üéì Wissenschaftlicher Vortrag (PDF)
                    """)
                
                with col3:
                    st.markdown("""
                    **Praxismaterialien**
                    - üìã Screening-Fragebogen
                    - üí° Interventionskatalog
                    - üìö Literaturliste
                    """)
            
            # ============================================
            # SUB-TAB 2: TECHNISCHE ANALYSE (ALT)
            # ============================================
            
            with subtab2:
                st.subheader("üìä Korrelation mit Matheleistung")
                
                # Korrelationen berechnen
                corr_data = []
                
                for var in selected_vars:
                    corr = df[[var, 'math_score']].corr().iloc[0, 1]
                    var_label = codebook[codebook['variable_name'] == var]['variable_label'].iloc[0]
                    
                    corr_data.append({
                        'Variable': var,
                        'Label': var_label[:50] + '...' if len(var_label) > 50 else var_label,
                        'Korrelation': round(corr, 3)
                    })
                
                corr_df = pd.DataFrame(corr_data).sort_values('Korrelation')
                
                st.dataframe(corr_df, use_container_width=True)
                
                # Visualisierung
                fig = px.bar(
                    corr_df,
                    x='Korrelation',
                    y='Variable',
                    orientation='h',
                    title='Korrelation mit Matheleistung (PV1MATH)',
                    color='Korrelation',
                    color_continuous_scale='RdYlGn_r',
                    range_color=[-0.5, 0.5]
                )
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
                
                st.info("üìå **Interpretation:** Negative Korrelation = h√∂here Anxiety ‚Üí niedrigere Matheleistung")
                
                # Correlation Matrix (wenn Composite Score existiert)
                if 'confidence_score' in df.columns:
                    st.subheader("üî¢ Korrelationsmatrix")
                    
                    corr_matrix = df[['confidence_score', 'math_score', 'reading_score', 'science_score']].corr()
                    
                    fig = px.imshow(
                        corr_matrix,
                        text_auto='.2f',
                        aspect='auto',
                        color_continuous_scale='RdYlGn',
                        zmin=-1,
                        zmax=1,
                        title='Korrelationen: Confidence Score & PISA Scores'
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
    
    # ============================================
    # TAB 4: VISUALISIERUNGEN
    # ============================================
    
    with tab4:
        st.header("üìà Visualisierungen")
        
        if 'df' in locals() and 'confidence_score' in df.columns:
            
            # Gender Gap Analysis
            st.subheader("üë´ Gender Gap - Mathematics Self-Confidence")
            
            # Filter f√ºr Gender
            df_gender = df[df['gender'].isin([1, 2])].copy()
            df_gender['gender_label'] = df_gender['gender'].map({1: 'M√§dchen', 2: 'Jungen'})
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Boxplot
                fig = px.box(
                    df_gender,
                    x='gender_label',
                    y='confidence_score',
                    color='gender_label',
                    title='Confidence Score nach Geschlecht',
                    labels={'gender_label': 'Geschlecht', 'confidence_score': 'Confidence Score (1-4)'},
                    color_discrete_map={'M√§dchen': '#FF6B9D', 'Jungen': '#4ECDC4'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Violin Plot
                fig = px.violin(
                    df_gender,
                    x='gender_label',
                    y='math_score',
                    color='gender_label',
                    box=True,
                    title='Matheleistung nach Geschlecht',
                    labels={'gender_label': 'Geschlecht', 'math_score': 'Math Score (PISA)'},
                    color_discrete_map={'M√§dchen': '#FF6B9D', 'Jungen': '#4ECDC4'}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # Statistik-Vergleich
            st.subheader("üìä Statistischer Vergleich")
            
            gender_stats = df_gender.groupby('gender_label')[['confidence_score', 'math_score']].agg(['mean', 'std', 'count'])
            st.dataframe(gender_stats, use_container_width=True)
            
            # Scatter: Confidence vs. Performance
            st.subheader("üîç Confidence Score vs. Matheleistung")
            
            fig = px.scatter(
                df_gender,
                x='confidence_score',
                y='math_score',
                color='gender_label',
                trendline='ols',
                title='Zusammenhang: Math Confidence & Performance',
                labels={
                    'confidence_score': 'Confidence Score (1=niedrig, 4=hoch)',
                    'math_score': 'Math Score (PISA)',
                    'gender_label': 'Geschlecht'
                },
                color_discrete_map={'M√§dchen': '#FF6B9D', 'Jungen': '#4ECDC4'},
                opacity=0.6
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Distribution Comparison
            st.subheader("üìä Verteilungen im Vergleich")
            
            fig = go.Figure()
            
            for gender in ['M√§dchen', 'Jungen']:
                data = df_gender[df_gender['gender_label'] == gender]['confidence_score']
                fig.add_trace(go.Histogram(
                    x=data,
                    name=gender,
                    opacity=0.7,
                    nbinsx=20
                ))
            
            fig.update_layout(
                barmode='overlay',
                title='Verteilung: Confidence Score nach Geschlecht',
                xaxis_title='Confidence Score',
                yaxis_title='Anzahl Sch√ºler',
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        else:
            st.warning("‚ö†Ô∏è Bitte berechne erst den Composite Score in Tab 2.")
    
    # ============================================
    # TAB 5: TIMSS-PISA MAPPING
    # ============================================
    
    with tab5:
        st.header("üó∫Ô∏è TIMSS-PISA Mapping Tool")
        
        st.markdown("""
        Erstelle ein **Mapping** zwischen TIMSS Mathematics Self-Confidence Items 
        und entsprechenden PISA-Variablen.
        """)
        
        # TIMSS Items (aus dem Wochenplan)
        timss_items = [
            {
                'dimension': 'Positive Self-Perception',
                'item': '"I usually do well in mathematics"',
                'construct': 'Self-Efficacy (positiv)'
            },
            {
                'dimension': 'Comparative Difficulty',
                'item': '"Mathematics is harder for me than for many of my classmates"',
                'construct': 'Social Comparison (negativ)'
            },
            {
                'dimension': 'Negative Self-Perception',
                'item': '"I am just not good at mathematics"',
                'construct': 'Fixed Mindset (negativ)'
            },
            {
                'dimension': 'Learning Speed',
                'item': '"I learn mathematics quickly"',
                'construct': 'Self-Efficacy (Learning)'
            }
        ]
        
        st.subheader("üìã TIMSS Reference Items")
        timss_df = pd.DataFrame(timss_items)
        st.dataframe(timss_df, use_container_width=True)
        
        st.markdown("---")
        
        # PISA Kandidaten
        st.subheader("üéØ PISA-Kandidaten f√ºr Mapping")
        
        pisa_candidates = find_math_confidence_vars(conn)
        
        # Filter f√ºr die wichtigsten
        priority_vars = ['ST182Q01HA', 'ST182Q02HA', 'ST182Q03HA', 'ST182Q04HA', 'ST182Q05HA']
        pisa_priority = pisa_candidates[pisa_candidates['variable_name'].isin(priority_vars)]
        
        if len(pisa_priority) > 0:
            st.markdown("**üìå Top-Kandidaten (Math Anxiety Items):**")
            
            # F√ºge Fragetexte hinzu falls vorhanden
            for _, row in pisa_priority.iterrows():
                var_name = row['variable_name']
                var_label = row['variable_label']
                
                with st.expander(f"**{var_name}** - {var_label[:60]}..."):
                    # Lade Fragetext
                    question = load_question_text(conn, var_name)
                    if question is not None and pd.notna(question.get('question_text_en')):
                        if pd.notna(question.get('question_text_de')):
                            st.markdown(f"**üá©üá™ Fragetext:** {question['question_text_de']}")
                        else:
                            st.markdown(f"**üá¨üáß Question:** {question['question_text_en']}")

                    # Lade Value Labels
                    value_labels = load_value_labels(conn, var_name)
                    if len(value_labels) > 0:
                        st.markdown("**Antwortoptionen:**")
                        for _, vl in value_labels.iterrows():
                            label = vl['label_de'] if pd.notna(vl.get('label_de')) else vl['label']
                            st.text(f"  {vl['value']} = {label}")
        
        st.markdown("**üìã Alle Math-Confidence Variablen:**")
        st.dataframe(pisa_candidates, use_container_width=True)
        
        st.markdown("---")
        
        # Interaktives Mapping
        st.subheader("üîó Erstelle dein Mapping")
        
        mapping_data = []
        
        for i, timss in enumerate(timss_items):
            with st.expander(f"**TIMSS Dimension {i+1}:** {timss['dimension']}"):
                st.markdown(f"**Item:** {timss['item']}")
                st.markdown(f"**Konstrukt:** {timss['construct']}")
                
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    selected_pisa = st.selectbox(
                        "W√§hle passendes PISA-Item:",
                        options=['---'] + pisa_candidates['variable_name'].tolist(),
                        key=f"mapping_{i}"
                    )
                
                with col2:
                    if selected_pisa != '---':
                        pisa_label = pisa_candidates[
                            pisa_candidates['variable_name'] == selected_pisa
                        ]['variable_label'].iloc[0]
                        
                        st.info(f"**Label:** {pisa_label[:100]}...")
                
                # Zeige Fragetext und Value Labels wenn Variable ausgew√§hlt
                if selected_pisa != '---':
                    st.markdown("---")

                    # Fragetext
                    question = load_question_text(conn, selected_pisa)
                    if question is not None and pd.notna(question.get('question_text_en')):
                        st.markdown("**üìù Vollst√§ndiger Fragetext:**")
                        if pd.notna(question.get('question_text_de')):
                            st.text(f"üá©üá™ {question['question_text_de']}")
                        else:
                            st.text(f"üá¨üáß {question['question_text_en']}")

                    # Value Labels
                    value_labels = load_value_labels(conn, selected_pisa)
                    if len(value_labels) > 0:
                        st.markdown("**Antwortoptionen:**")
                        for _, vl in value_labels.iterrows():
                            label = vl['label_de'] if pd.notna(vl.get('label_de')) else vl['label']
                            st.text(f"  {vl['value']} = {label}")
                    
                    # F√ºge zu Mapping hinzu
                    mapping_data.append({
                        'TIMSS Dimension': timss['dimension'],
                        'TIMSS Item': timss['item'],
                        'TIMSS Konstrukt': timss['construct'],
                        'PISA Variable': selected_pisa,
                        'PISA Label': pisa_label,
                        'PISA Fragetext': question['question_text_de'] if question is not None and pd.notna(question.get('question_text_de')) 
                                         else (question['question_text_en'] if question is not None else 'N/A')
                    })
        
        # Mapping-√úbersicht
        if mapping_data:
            st.markdown("---")
            st.subheader("‚úÖ Dein TIMSS-PISA Mapping")
            
            mapping_df = pd.DataFrame(mapping_data)
            st.dataframe(mapping_df, use_container_width=True)
            
            # Download als CSV
            csv = mapping_df.to_csv(index=False)
            st.download_button(
                label="üì• Mapping als CSV herunterladen",
                data=csv,
                file_name="timss_pisa_mapping.csv",
                mime="text/csv"
            )
    
    # ============================================
    # TAB 6: ERGEBNIS√úBERSICHT & EXPORT
    # ============================================
    
    with tab6:
        st.header("üìã Ergebnis√ºbersicht & Export")
        st.markdown("*Alle Kennzahlen auf einen Blick - bereit zum Weiterarbeiten*")
        
        # Check ob Daten verf√ºgbar
        if 'df' not in locals() or not selected_vars:
            st.warning("""
            ‚ö†Ô∏è **Noch keine Analyse durchgef√ºhrt**
            
            Bitte gehe zu Tab 2 und w√§hle Variablen aus, um eine Analyse zu starten.
            Dann kannst du hier alle Ergebnisse √ºbersichtlich sehen und exportieren.
            """)
        else:
            # ============================================
            # SECTION 1: STICHPROBENINFO
            # ============================================
            
            st.subheader("1Ô∏è‚É£ Stichprobeninformation")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "Stichprobengr√∂√üe",
                    f"{len(df):,}",
                    help="Anzahl Sch√ºler in der Analyse"
                )
            
            with col2:
                st.metric(
                    "Datenbank",
                    "pisa_2022_germany",
                    help="Verwendete Datenbank"
                )
            
            with col3:
                st.metric(
                    "Analysierte Variablen",
                    len(selected_vars),
                    help="Anzahl ausgew√§hlter Variablen"
                )
            
            with col4:
                st.metric(
                    "Analysedatum",
                    pd.Timestamp.now().strftime("%Y-%m-%d"),
                    help="Datum der Analyse"
                )
            
            st.markdown("**Ausgew√§hlte Variablen:**")
            st.code(", ".join(selected_vars), language=None)
            
            st.markdown("---")
            
            # ============================================
            # SECTION 2: DESKRIPTIVE STATISTIKEN
            # ============================================
            
            st.subheader("2Ô∏è‚É£ Deskriptive Statistiken")
            
            # Erstelle √úbersichtstabelle
            desc_data = []
            
            for var in selected_vars:
                desc_data.append({
                    'Variable': var,
                    'N': df[var].count(),
                    'Mean': df[var].mean(),
                    'SD': df[var].std(),
                    'Min': df[var].min(),
                    'Max': df[var].max(),
                    'Missing': df[var].isnull().sum(),
                    'Missing %': (df[var].isnull().sum() / len(df) * 100)
                })
            
            # Matheleistung hinzuf√ºgen
            desc_data.append({
                'Variable': 'math_score',
                'N': df['math_score'].count(),
                'Mean': df['math_score'].mean(),
                'SD': df['math_score'].std(),
                'Min': df['math_score'].min(),
                'Max': df['math_score'].max(),
                'Missing': df['math_score'].isnull().sum(),
                'Missing %': (df['math_score'].isnull().sum() / len(df) * 100)
            })
            
            desc_df = pd.DataFrame(desc_data)
            
            # Formatierung
            desc_df_display = desc_df.copy()
            desc_df_display['Mean'] = desc_df_display['Mean'].apply(lambda x: f"{x:.3f}")
            desc_df_display['SD'] = desc_df_display['SD'].apply(lambda x: f"{x:.3f}")
            desc_df_display['Min'] = desc_df_display['Min'].apply(lambda x: f"{x:.2f}")
            desc_df_display['Max'] = desc_df_display['Max'].apply(lambda x: f"{x:.2f}")
            desc_df_display['Missing %'] = desc_df_display['Missing %'].apply(lambda x: f"{x:.1f}%")
            
            st.dataframe(desc_df_display, use_container_width=True, hide_index=True)
            
            st.markdown("---")
            
            # ============================================
            # SECTION 3: KORRELATIONEN
            # ============================================
            
            st.subheader("3Ô∏è‚É£ Korrelationen mit Mathematikleistung")
            
            # Berechne Korrelationen
            corr_data = []
            
            for var in selected_vars:
                corr = df[[var, 'math_score']].corr().iloc[0, 1]
                r2 = corr ** 2
                
                # Effektst√§rken-Klassifikation nach Cohen (1988)
                if abs(corr) < 0.1:
                    effect_size = "Sehr klein"
                elif abs(corr) < 0.3:
                    effect_size = "Klein"
                elif abs(corr) < 0.5:
                    effect_size = "Mittel"
                else:
                    effect_size = "Gro√ü"
                
                corr_data.append({
                    'Variable': var,
                    'r': corr,
                    'r (absolut)': abs(corr),
                    'R¬≤': r2,
                    'R¬≤ (%)': r2 * 100,
                    'Effektst√§rke': effect_size,
                    'Richtung': 'Positiv' if corr > 0 else 'Negativ'
                })
            
            corr_df = pd.DataFrame(corr_data).sort_values('r (absolut)', ascending=False)
            
            # Formatierung
            corr_df_display = corr_df.copy()
            corr_df_display['r'] = corr_df_display['r'].apply(lambda x: f"{x:.3f}")
            corr_df_display['r (absolut)'] = corr_df_display['r (absolut)'].apply(lambda x: f"{x:.3f}")
            corr_df_display['R¬≤'] = corr_df_display['R¬≤'].apply(lambda x: f"{x:.3f}")
            corr_df_display['R¬≤ (%)'] = corr_df_display['R¬≤ (%)'].apply(lambda x: f"{x:.1f}%")
            
            st.dataframe(corr_df_display, use_container_width=True, hide_index=True)
            
            # Highlight st√§rkste Korrelation
            strongest = corr_df.iloc[0]
            st.success(f"""
            **üèÜ St√§rkster Pr√§diktor:** {strongest['Variable']} 
            (r = {strongest['r']:.3f}, R¬≤ = {strongest['R¬≤ (%)']:.1f}%)
            """)
            
            st.markdown("---")
            
            # ============================================
            # SECTION 4: QUADRANTEN-ANALYSE
            # ============================================
            
            if 'ANXMAT' in selected_vars and 'MATHEFF' in selected_vars:
                st.subheader("4Ô∏è‚É£ Quadranten-Analyse")
                
                # Berechne Quadranten (schon in Tab 3 gemacht, hier nochmal)
                median_matheff = df['MATHEFF'].median()
                median_anxmat = df['ANXMAT'].median()
                
                df['quadrant'] = 'Q4'
                df.loc[(df['MATHEFF'] >= median_matheff) & (df['ANXMAT'] < median_anxmat), 'quadrant'] = 'Q1'
                df.loc[(df['MATHEFF'] >= median_matheff) & (df['ANXMAT'] >= median_anxmat), 'quadrant'] = 'Q2'
                df.loc[(df['MATHEFF'] < median_matheff) & (df['ANXMAT'] >= median_anxmat), 'quadrant'] = 'Q3'
                df.loc[(df['MATHEFF'] < median_matheff) & (df['ANXMAT'] < median_anxmat), 'quadrant'] = 'Q4'
                
                # Statistik pro Quadrant
                quadrant_stats = df.groupby('quadrant').agg({
                    'math_score': ['mean', 'std', 'count']
                }).round(2)
                quadrant_stats.columns = ['√ò Leistung', 'SD Leistung', 'N']
                quadrant_stats['Anteil %'] = (quadrant_stats['N'] / len(df) * 100).round(1)
                
                # Labels
                quadrant_stats.index = quadrant_stats.index.map({
                    'Q1': 'Q1: Optimal (Hoch/Niedrig)',
                    'Q2': 'Q2: Ambivalent (Hoch/Hoch)',
                    'Q3': 'Q3: Risikogruppe (Niedrig/Hoch)',
                    'Q4': 'Q4: Indifferent (Niedrig/Niedrig)'
                })
                
                st.dataframe(quadrant_stats, use_container_width=True)
                
                # Risikogruppe hervorheben
                q3_n = quadrant_stats.loc['Q3: Risikogruppe (Niedrig/Hoch)', 'N']
                q3_pct = quadrant_stats.loc['Q3: Risikogruppe (Niedrig/Hoch)', 'Anteil %']
                q3_perf = quadrant_stats.loc['Q3: Risikogruppe (Niedrig/Hoch)', '√ò Leistung']
                
                st.warning(f"""
                **‚ö†Ô∏è Risikogruppe (Q3):**
                - {q3_n:.0f} Sch√ºler ({q3_pct:.1f}% der Stichprobe)
                - Durchschnittsleistung: {q3_perf:.0f} Punkte
                - Intervention empfohlen: Fokus auf Selbstwirksamkeitsf√∂rderung
                """)
                
                st.markdown("---")
            
            # ============================================
            # SECTION 5: KEY FINDINGS
            # ============================================
            
            st.subheader("5Ô∏è‚É£ Key Findings")
            
            st.markdown("**üìå Zusammenfassung der wichtigsten Erkenntnisse:**")
            
            # Dynamisch generierte Key Findings
            findings = []
            
            # Finding 1: Stichprobe
            findings.append(f"**Stichprobe:** N = {len(df):,} Sch√ºler aus PISA 2022 Deutschland")
            
            # Finding 2: St√§rkster Pr√§diktor
            if len(corr_df) > 0:
                strongest = corr_df.iloc[0]
                findings.append(
                    f"**St√§rkster Pr√§diktor:** {strongest['Variable']} mit r = {strongest['r']:.3f} "
                    f"(R¬≤ = {strongest['R¬≤ (%)']:.1f}%, Effektst√§rke: {strongest['Effektst√§rke']})"
                )
            
            # Finding 3: MATHEFF vs ANXMAT
            if 'ANXMAT' in selected_vars and 'MATHEFF' in selected_vars:
                corr_matheff = corr_df[corr_df['Variable'] == 'MATHEFF']['r'].values[0]
                corr_anxmat = corr_df[corr_df['Variable'] == 'ANXMAT']['r'].values[0]
                ratio = abs(float(corr_matheff) / float(corr_anxmat))
                
                findings.append(
                    f"**Selbstwirksamkeit vs. Angst:** MATHEFF (r = {float(corr_matheff):.3f}) ist "
                    f"{ratio:.2f}x einflussreicher als ANXMAT (r = {float(corr_anxmat):.3f})"
                )
                
                # Finding 4: Risikogruppe
                findings.append(
                    f"**Risikogruppe:** {q3_n:.0f} Sch√ºler ({q3_pct:.1f}%) mit niedriger "
                    f"Selbstwirksamkeit UND hoher Angst ‚Üí Priorit√§t f√ºr Interventionen"
                )
            
            # Finding 5: Durchschnittsleistung
            mean_math = df['math_score'].mean()
            if mean_math < 482:
                pisa_level = "Level 2 (Basiskompetenzen)"
            elif mean_math < 545:
                pisa_level = "Level 3 (Solide Kenntnisse)"
            elif mean_math < 607:
                pisa_level = "Level 4 (Gut)"
            else:
                pisa_level = "Level 5+ (Sehr gut)"
            
            findings.append(
                f"**Durchschnittsleistung:** {mean_math:.0f} PISA-Punkte ‚Üí {pisa_level}"
            )
            
            # Ausgabe
            for i, finding in enumerate(findings, 1):
                st.markdown(f"{i}. {finding}")
            
            st.markdown("---")
            
            # ============================================
            # SECTION 6: HANDLUNGSEMPFEHLUNGEN
            # ============================================
            
            st.subheader("6Ô∏è‚É£ Handlungsempfehlungen")
            
            recommendations = []
            
            if 'MATHEFF' in selected_vars:
                corr_matheff_val = float(corr_df[corr_df['Variable'] == 'MATHEFF']['r'].values[0])
                if abs(corr_matheff_val) > 0.5:
                    recommendations.append({
                        'Priorit√§t': 'üî¥ Hoch',
                        'Bereich': 'Selbstwirksamkeitsf√∂rderung',
                        'Ma√ünahme': 'Mastery Experiences: Strukturierte Erfolgserlebnisse schaffen',
                        'Begr√ºndung': f'Starke Korrelation (r = {corr_matheff_val:.3f}) rechtfertigt Fokus'
                    })
            
            if 'ANXMAT' in selected_vars:
                corr_anxmat_val = float(corr_df[corr_df['Variable'] == 'ANXMAT']['r'].values[0])
                if abs(corr_anxmat_val) > 0.3:
                    recommendations.append({
                        'Priorit√§t': 'üü° Mittel',
                        'Bereich': 'Angstreduktion',
                        'Ma√ünahme': 'Kognitive Umstrukturierung & Entspannungstechniken',
                        'Begr√ºndung': f'Mittlere Korrelation (r = {corr_anxmat_val:.3f})'
                    })
            
            if 'ANXMAT' in selected_vars and 'MATHEFF' in selected_vars and q3_pct > 15:
                recommendations.append({
                    'Priorit√§t': 'üî¥ Hoch',
                    'Bereich': 'Risikogruppen-Intervention',
                    'Ma√ünahme': 'Individuelle F√∂rderung f√ºr Q3-Sch√ºler (niedrige SE + hohe Angst)',
                    'Begr√ºndung': f'{q3_pct:.1f}% der Sch√ºler in kritischer Konstellation'
                })
            
            recommendations.append({
                'Priorit√§t': 'üü¢ Basis',
                'Bereich': 'Diagnostik',
                'Ma√ünahme': 'Regelm√§√üiges Screening von Selbstwirksamkeit & Angst',
                'Begr√ºndung': 'Fr√ºherkennung erm√∂glicht rechtzeitige Intervention'
            })
            
            rec_df = pd.DataFrame(recommendations)
            st.dataframe(rec_df, use_container_width=True, hide_index=True)
            
            st.markdown("---")
            
            # ============================================
            # SECTION 7: EXPORT
            # ============================================
            
            st.subheader("7Ô∏è‚É£ Daten exportieren")
            
            st.markdown("""
            **Lade alle Ergebnisse herunter f√ºr:**
            - Weiterverarbeitung in Excel/SPSS
            - Integration in Berichte
            - Pr√§sentationen & Fortbildungen
            """)
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("### üìä Deskriptive Statistiken")
                
                # CSV Download
                csv_desc = desc_df.to_csv(index=False)
                st.download_button(
                    label="üì• CSV herunterladen",
                    data=csv_desc,
                    file_name=f"pisa_deskriptiv_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv",
                    key="download_desc"
                )
            
            with col2:
                st.markdown("### üîó Korrelationen")
                
                # CSV Download
                csv_corr = corr_df.to_csv(index=False)
                st.download_button(
                    label="üì• CSV herunterladen",
                    data=csv_corr,
                    file_name=f"pisa_korrelationen_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv",
                    key="download_corr"
                )
            
            with col3:
                if 'quadrant_stats' in locals():
                    st.markdown("### üó∫Ô∏è Quadranten")
                    
                    # CSV Download
                    csv_quad = quadrant_stats.to_csv()
                    st.download_button(
                        label="üì• CSV herunterladen",
                        data=csv_quad,
                        file_name=f"pisa_quadranten_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                        mime="text/csv",
                        key="download_quad"
                    )
            
            st.markdown("---")
            
            # EXCEL-Export mit allen Sheets
            st.markdown("### üìó Kompletter Export (Excel mit allen Sheets)")
            
            try:
                from io import BytesIO
                
                # Erstelle Excel-Datei im Speicher
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    # Sheet 1: √úbersicht
                    overview_data = {
                        'Kennzahl': [
                            'Stichprobengr√∂√üe',
                            'Datenbank',
                            'Analysierte Variablen',
                            'Analysedatum',
                            'Durchschnittsleistung',
                            'PISA-Level'
                        ],
                        'Wert': [
                            len(df),
                            "pisa_2022_germany.db",
                            ', '.join(selected_vars),
                            pd.Timestamp.now().strftime('%Y-%m-%d'),
                            f"{mean_math:.0f}",
                            pisa_level
                        ]
                    }
                    pd.DataFrame(overview_data).to_excel(writer, sheet_name='√úbersicht', index=False)
                    
                    # Sheet 2: Deskriptive Statistiken
                    desc_df.to_excel(writer, sheet_name='Deskriptive Statistiken', index=False)
                    
                    # Sheet 3: Korrelationen
                    corr_df.to_excel(writer, sheet_name='Korrelationen', index=False)
                    
                    # Sheet 4: Quadranten (falls vorhanden)
                    if 'quadrant_stats' in locals():
                        quadrant_stats.to_excel(writer, sheet_name='Quadranten-Analyse')
                    
                    # Sheet 5: Key Findings
                    findings_data = {
                        'Nr': range(1, len(findings) + 1),
                        'Finding': findings
                    }
                    pd.DataFrame(findings_data).to_excel(writer, sheet_name='Key Findings', index=False)
                    
                    # Sheet 6: Handlungsempfehlungen
                    rec_df.to_excel(writer, sheet_name='Handlungsempfehlungen', index=False)
                
                excel_data = output.getvalue()
                
                st.download_button(
                    label="üì• Alle Ergebnisse als Excel herunterladen",
                    data=excel_data,
                    file_name=f"pisa_analyse_komplett_{pd.Timestamp.now().strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_excel"
                )
                
                st.success("‚úÖ Excel-Export mit 6 Sheets: √úbersicht, Deskriptive Statistiken, Korrelationen, Quadranten-Analyse, Key Findings, Handlungsempfehlungen")
                
            except ImportError:
                st.error("‚ö†Ô∏è Excel-Export ben√∂tigt 'openpyxl'. Bitte installiere: `pip install openpyxl --break-system-packages`")
            
            st.markdown("---")
            
            # ============================================
            # SECTION 8: COPY-PASTE ZUSAMMENFASSUNG
            # ============================================
            
            st.subheader("8Ô∏è‚É£ Copy-Paste Zusammenfassung")
            
            st.markdown("**F√ºr Berichte, E-Mails, Pr√§sentationen:**")
            
            summary_text = f"""
PISA 2022 Deutschland - Analyse Affektiver Faktoren
Analysedatum: {pd.Timestamp.now().strftime('%Y-%m-%d')}

STICHPROBE
- N = {len(df):,} Sch√ºler
- Analysierte Variablen: {', '.join(selected_vars)}
- Durchschnittsleistung: {mean_math:.0f} PISA-Punkte ({pisa_level})

ZENTRALE BEFUNDE
"""
            
            for i, finding in enumerate(findings, 1):
                # Entferne Markdown-Formatierung f√ºr Plain Text
                clean_finding = finding.replace('**', '').replace('*', '')
                summary_text += f"{i}. {clean_finding}\n"
            
            summary_text += f"""
KORRELATIONEN MIT MATHEMATIKLEISTUNG
"""
            
            for _, row in corr_df.iterrows():
                summary_text += f"- {row['Variable']}: r = {row['r']:.3f} (R¬≤ = {row['R¬≤ (%)']:.1f}%, {row['Effektst√§rke']})\n"
            
            if 'quadrant_stats' in locals():
                summary_text += f"""
QUADRANTEN-ANALYSE
- Q1 (Optimal): {quadrant_stats.loc['Q1: Optimal (Hoch/Niedrig)', 'Anteil %']:.1f}% ({quadrant_stats.loc['Q1: Optimal (Hoch/Niedrig)', '√ò Leistung']:.0f} Punkte)
- Q2 (Ambivalent): {quadrant_stats.loc['Q2: Ambivalent (Hoch/Hoch)', 'Anteil %']:.1f}% ({quadrant_stats.loc['Q2: Ambivalent (Hoch/Hoch)', '√ò Leistung']:.0f} Punkte)
- Q3 (Risikogruppe): {quadrant_stats.loc['Q3: Risikogruppe (Niedrig/Hoch)', 'Anteil %']:.1f}% ({quadrant_stats.loc['Q3: Risikogruppe (Niedrig/Hoch)', '√ò Leistung']:.0f} Punkte)
- Q4 (Indifferent): {quadrant_stats.loc['Q4: Indifferent (Niedrig/Niedrig)', 'Anteil %']:.1f}% ({quadrant_stats.loc['Q4: Indifferent (Niedrig/Niedrig)', '√ò Leistung']:.0f} Punkte)

HANDLUNGSEMPFEHLUNGEN
"""
            
            for _, rec in rec_df.iterrows():
                summary_text += f"{rec['Priorit√§t']} {rec['Bereich']}: {rec['Ma√ünahme']}\n"
            
            st.text_area(
                "Kopiere diesen Text:",
                summary_text,
                height=400,
                key="copy_summary"
            )
            
            st.info("üí° **Tipp:** Klicke in das Textfeld und dr√ºcke Ctrl+A (alles markieren) dann Ctrl+C (kopieren)")
    
    # ============================================
    # SIDEBAR: INFO
    # ============================================
    
    st.sidebar.markdown("---")
    st.sidebar.header("‚ÑπÔ∏è Info")
    st.sidebar.markdown("""
    **PISA 2022 Deutschland**
    
    Diese App analysiert:
    - Mathematics Self-Confidence
    - Mathematics Anxiety
    - Mathematics Self-Efficacy
    
    **Datenquelle:** PISA 2022 Deutschland-Datenbank
    
    **Autor:** Sandra
    **Datum:** Oktober 2025
    """)

if __name__ == "__main__":
    main()